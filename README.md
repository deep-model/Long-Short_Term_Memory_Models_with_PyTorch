
# Long Short-Term Memory Models with PyTorch

## University of Houston Victoria 
### Matthew Harper 
    
## **Deep Learning Topic Areas:      
Recurrent Networks   Feedforward MLPs    Principal Component Analysis       
Linear Factor Models   Non-linear Activation      Long Short-Term Memory 
Deep Networks    Sparse Coding  

**Abstract**: Linear factor models arguably present some of the more simplistic methods for developing generative models with latent variables [2]. 
Linear factor models utilize probabilistic inference to predict a variable value given other independent variables and are often used to build 
larger deep probabilistic models [1, 2]. Moreover, a linear factor model can be further defined as a stochastic model or a model well described 
by a random probability distribution which uses a linear decoder function to generate value x by adding noise to a linear transformation. As a 
result, principal component analysis (PCA) and sparse coding are special cases of linear factor models which have demonstrated promising results
for variable selection, reduced dimensionality, and noise reduction [2]. In addition, this project extends the rigors of recurrent networks and 
introduces Long Short-Term Memory models for applications in image recognition training and test models using PyTorch with optimizations methods
to reduce long term dependencies and gradient anomalies [1].
