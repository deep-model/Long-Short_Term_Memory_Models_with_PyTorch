# -*- coding: utf-8 -*-
"""Deep Learning LSTM Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-ItZeTHB7FvcPiJj9sKtCt3ANI2C9uN7

# Deep Learning
# Long Short-Term Memory Models with PyTorch
# Matthew Harper

# Step 1: Setting up the environment
"""

#This code snippet allows to use data directly from your Google drives files.
#If you want to use a shared folder, just add the folder to your drive
from google.colab import drive
drive.mount('/content/gdrive')

"""# Step 2: Setting up the 3D python context"""

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits import mplot3d
from sklearn.cluster import KMeans
from sklearn.cluster import DBSCAN

"""# Step 3 Create the data folder paths and upload KME.xyz 3D files"""

from google.colab import files
uploaded = files.upload()

#create paths and load data
data_folder="/content"
result_folder="/content"

#Load the file
dataset="/content/KME_planes.xyz"

#store features in x,y,z,illuminance,reflectance,intensity and nb_of_returns variable
#https://drive.google.com/drive/folders/1Ih_Zz9a6UcbUlaA-puEB_is7DYvXrb4w
x,y,z,illuminance,reflectance,intensity,nb_of_returns = np.loadtxt("/content/KME_planes.xyz",skiprows=1, delimiter=';', unpack=True)

"""# Step 4: Point Cloud quick selection"""

plt.subplot(1, 2, 1) # row 1, col 2 index 1
plt.scatter(x, z, c=intensity, s=0.05)
plt.axhline(y=np.mean(z), color='r', linestyle='-')
plt.title("First view")
plt.xlabel('X-axis ')
plt.ylabel('Z-axis ')

plt.subplot(1, 2, 2) # index 2
plt.scatter(y, z, c=intensity, s=0.05)
plt.axhline(y=np.mean(z), color='r', linestyle='-')
plt.title("Second view")
plt.xlabel('Y-axis ')
plt.ylabel('Z-axis ')

plt.show()

"""# Step 5: Point CLoud Filtering"""

pcd=np.column_stack((x,y,z))
mask=z>np.mean(z)
spatial_query=pcd[z>np.mean(z)]

#plotting the results 3D
ax = plt.axes(projection='3d')
ax.scatter(x[mask], y[mask], z[mask], c = intensity[mask], s=0.1)
plt.show()

#plotting the results 2D
plt.scatter(x[mask], y[mask], c=intensity[mask], s=0.1)
plt.show()

X=np.column_stack((x[mask], y[mask]))
kmeans = KMeans(n_clusters=2).fit(X)
plt.scatter(x[mask], y[mask], c=kmeans.labels_, s=0.1)
plt.show()

"""# Step 6: K-Means CLustering"""

import warnings
warnings.filterwarnings("ignore")

X=np.column_stack((x[mask], y[mask], z[mask]))
wcss = []
for i in range(1, 20):
 kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
 kmeans.fit(X)
 wcss.append(kmeans.inertia_)

#plot Elbow method
plt.plot(range(1, 20), wcss)
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

#playing with the features
X=np.column_stack((x[mask], y[mask], z[mask], illuminance[mask], nb_of_returns[mask], intensity[mask]))
kmeans = KMeans(n_clusters=3, random_state=0).fit(X)
plt.scatter(x[mask], y[mask], c=kmeans.labels_, s=0.1)
plt.show()

np.savetxt(dataset.split(".")[0]+"_result.xyz", np.column_stack((x[mask], y[mask], z[mask],kmeans.labels_)), fmt='%1.4f', delimiter=';')









